{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "y2mfq24pyvjtb7623o3f",
   "authorId": "217400574159",
   "authorName": "JHEISLER",
   "authorEmail": "john.heisler@snowflake.com",
   "sessionId": "e7edfbda-8297-433d-9aa5-11ff70cb11c0",
   "lastEditTime": 1738791393134
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "530ddf9c-b439-440a-8a64-355acf3ed172",
   "metadata": {
    "name": "md_synopsis",
    "collapsed": false,
    "resultHeight": 2228
   },
   "source": "# **Change Request Risk Assessment with Cortex AI**\n#### Author: **John Heisler** - Senior AI Specialist, Financial Services, Snowflake\nIn this notebook, we're going to evaluate a new change request and determine a risk score for that change request resulting in target environment instability.\n\nThe notebook is written to allow deployment directly into anyone's environment.\n\n## Cortex AI Commercial Value\n\nUltimately, AI should drive commercial value. To that end, building, deploying, and maintaining the systems that underpin that commercial value need to be easy, efficient, and trusted. \n\nWith Cortex AI, we balance complexity encapsulation with complexity exposure to maximize the time to value with AI. \n\n### Hit the Nail, Don't Build the Hammer!\nEnterprises that maximize efforts leveraging their differentiated domain knowledge and creativity will ultimately win the AI race. Every ounce of effort spent on managing/building/tuning AI is a distraction from delivering value and thus comes at a material opportunity cost. With Snowflake Cortex AI, we aim to maximize efforts wielding the power of AI, not building it.\n\n## Use Case Commercial Value\nOur solution drives **operational alpha** by maximizing uptime of production environments. This solution provides operational alpha in at least these four ways:\n1. **System Uptime**: The systems critical to support our portfolio teams will be more stable and provide maximum value to our portfolio teams' performance.\n2. **Regulatory Reporting**: Minimize need for reporting to external regulators about critical system downtime and its impact.\n3. **Opportunity Cost**: Minimizing time spent conducting emergency maintenance which can be repurposed to focus on alpha-generating solutions.\n4. **Opportunity Cost**: Minimize need for time-and-resource-intensive root cause analysis and these cross functional teams can focus on their primary responsibilities.\n\n## Process Outline\nFirst, we will create and fill a change request table with some synthetic data (Fun Fact: You can use LLMs to do that. Check out how I did it in harbinger_data_creation.ipynb notebook in this repo). \n\nSecond, we will build a python function to house our prompt and accept a change request as context. this approach streamlines our code and decouples the prompt from our broader development, allowing for independent development on the prompt by domain experts.\n\nLast, we will build a Streamlit in Snowflake (SiS) front end to allow our end users to score new change requests.\n\n## Snowflake Differentiators\n* **LLM fungibility**: We have a model garden right here in Snowflake-- no need to manage divergent infrastructure and no need for external calls which introduce risk into your system\n* **Physics of data**: With snowflake, we can perform the inference with LLMs all in one spot. There is no need to dehydrate Snowflake and move externally \n* **Flexibility**: Snowpark Container Services would allow you to bring any model you want (or any functionality for that matter) to run right here in Snowflake. This opens the door to run anything in Snowflake to maximize performance, minimize overhead, and reap the benefits of a single governance framework.\n* **Access to Power**: We provide access to GPUs and infrastructure at your fingertips to turbo charge your development and performance. Again, this allows you to focus on driving value not button booping and knob twisting. \n\n## Art of the Possible\nHere is some food for thought and hopefully inspiring enhancements for your deployment. \n\n* **Fine Tuning**: If we have tied incidents' root causes to change requests in the past, we could fine tune a model here in Snowflake with that data and the task that we're after. This has a couple of very interesting advantages. first, we would have a very specialize model that may perform this task very well because it has \"experience\" with what good and bad looks like. More operationally focused, we could maybe use a smaller model maximizing cost efficiencies.\n* **More Context - Metadata**: we could offer much more context about what each column in the data set means and fully define the json structure that we're passing. This would inform the model on the meaning of each column rather than allowing it to come up with its best guess at the columns.\n* **More Context - Target System Stability (Windshield)**: We could use another LLM upstream of the final risk inference to build a synopsis of the target system stability and status. For instance, it could state things like, \"the target system for EDM-Account-Master has seen several out of memory alerts and disc space errors in the last six weeks.\" We would instruct the risk prompt to consider that environment when deriving its risk assessment which should enhance its predictions.\n* **More Context - Incident Root Causes (Rear view Mirror)**: We could pass a synopsis of the last 6 months of root causes to the model. This would make it keenly aware \n\n## Next Steps\n1. Try this out on your own data: You will be *blown away* by the results and how easy it is. \n2. Don't walk alone: You have access to AI experts that can guide your development to an accelerated outcome at no cost to you!"
  },
  {
   "cell_type": "markdown",
   "id": "2495c655-8b74-4188-87ab-4d357608b068",
   "metadata": {
    "name": "md_prompt_fucntion",
    "collapsed": false,
    "resultHeight": 74
   },
   "source": "# Create Prompt Function with Python"
  },
  {
   "cell_type": "code",
   "id": "59beacfd-a764-489e-ab93-80fc1e621c05",
   "metadata": {
    "language": "python",
    "name": "py_generate_risk_prediction_prompt",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "def generate_risk_prediction_prompt(cr_data):\n    prompt = f\"\"\"\n            <role>\n            You are an experienced dev ops professional deeply knowledgeable on computer systems that support a very large company and the metadata that is captured about change requests.\n            A change request is a formal proposal for an alteration to the computer system that you manage.\n            As a dev ops expert, you specialize in using the metadata provided about a change request to predict the liklihood of the change request unintentionally destabalizing the computer system.\n            You are going to be provided with change request meta data as a json object held between <cr_data> and your job is to provide a prediction score and reasoning behind the risk score in the <output> section. \n            </role>\n        \n            <task>: Follow these instructions,\n            1) Considering the <cr_data> and your <role>, provide a risk score between 0 to 5 of this change request destabalizing the computer system when deployed. do not exhibit a bias toward high risk. base your risk score only on the data you have been provided. if there is not enough information, please indicate this. Output this as [Risk_Score]. Then,\n            2) Considering the <cr_data> and your <role>, provide a reasoning for the risk score in as few words as possible while maintaining all detail needed to understand your reasoning. Output this as [Risk_Score_Reason]\n            </task>\n\n            <cr_data>\n            {cr_data}\n            </cr_data>\n        \n            <Output> \n            produce valid JSON. Absolutely do not include any additional text before or following the JSON. Output should use following <JSON_format>\n            </Output>\n            \n            <JSON_format>\n            {{\n                \"Risk_Score\": (A risk score between 0 to 5 of this change request destabalizing the computer system when deployed),\n                \"Risk_Score_Reason\": (A concise resoning for the Risk_Score and any suggestions to mitigate),\n            }}\n            </JSON_format>\n            \"\"\"\n    return prompt",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c93165dc-fae8-4d98-a81c-6450b4981625",
   "metadata": {
    "name": "md_my_complete",
    "collapsed": false
   },
   "source": "# my_complete() \n\nWe can call our LLMs via the LLM API (https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-llm-rest-api) or using SQL. To make passing our parameters easy, I am coing to use SQL and wrap it in a python function to call later."
  },
  {
   "cell_type": "code",
   "id": "5acf80bb-8c0c-41a6-a711-be778dc7b1e8",
   "metadata": {
    "language": "python",
    "name": "py_create_complete_function",
    "collapsed": false
   },
   "outputs": [],
   "source": "def my_complete(model, context, temp = 0, max_tokens: int = 18000):\n    sql = F\"\"\"SELECT SNOWFLAKE.CORTEX.COMPLETE(\n            '{model}',\n            [\n                {{\n                    'role': 'user',\n                    'content': '{context}'\n                }}\n            ],\n            {{\n                'max_tokens': {max_tokens}, \n                'temperature' : {temp}\n            }}\n        ) as inference;\"\"\"\n    inference_raw = session.sql(sql).to_pandas().loc[0,\"INFERENCE\"]\n    inference_json = json.loads(inference_raw)\n    inference_raw = inference_json['choices'][0]['messages']\n    return inference_raw",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "303c090f-351a-46a4-8ccb-e94759ce1106",
   "metadata": {
    "name": "md_risk_score",
    "collapsed": false,
    "resultHeight": 202
   },
   "source": "# Batch Inference\n## Generate Risk Score and Reasoning\n\n\n\n### 🤯 Whoa, check that out 🤯\nIn a single line of python (19), we compile our prompt and call our LLM for inference. We could swap ANY LLM WE WANT here with exactly 0 overhead. \n\nhttps://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions#availability"
  },
  {
   "cell_type": "markdown",
   "id": "3e81d7d6-905f-4044-ad33-86d2090c4cb6",
   "metadata": {
    "name": "md_SIS",
    "collapsed": false,
    "resultHeight": 115
   },
   "source": "# Make It Relevant with Streamlit in Snowflake\n\nBuilt but not accessible is the same as not built at all, we need to expose this functionlity to the end user. We will use Streamlit in Snowflake to do that. \n\nWe want to give the end user the abilility to interact with this data in two ways: \n1. first we want them to be able to see all of their change requests in a single place-- this would be great for a systematic or weekly review of changes. \n2. Give the end users a way to select a change request and use an LLM of their choosing to generate the risk score and reasoning.\n\n**Note**: I made the below available as a standalone Streamlit in Snowflake as well."
  },
  {
   "cell_type": "code",
   "id": "6671ee68-a4c5-4f0b-b695-29fe8a516d58",
   "metadata": {
    "language": "python",
    "name": "py_summary_streamlit",
    "collapsed": false
   },
   "outputs": [],
   "source": "import streamlit as st\nimport json5 as json\nimport pandas as pd\nfrom snowflake.snowpark.functions import col, call_udf\nfrom snowflake.snowpark.context import get_active_session\n\n# # Page configuration\n# st.set_page_config(\n#     page_title=\"Change Request Risk Assessment\",\n#     page_icon=\"🔍\",\n#     layout=\"wide\",\n#     initial_sidebar_state=\"expanded\"\n# )\n\n# Add legend for risk score colors\nst.sidebar.title('Risk Score Legend')\n\nfunctionality = st.sidebar.selectbox('Select Functionlity', (\"Summary\", \"Ad Hoc\"))\n\nlegend_cols = st.sidebar.columns(3)\nwith legend_cols[0]:\n    st.color_picker('Low Risk (0-2)', '#00FF00', disabled=True)\nwith legend_cols[1]:\n    st.color_picker('Medium Risk (2-3)', '#FFFF00', disabled=True)\nwith legend_cols[2]:\n    st.color_picker('High Risk (4-5)', '#FF0000', disabled=True)\n\n# Custom CSS for elegant styling\nst.write(\"\"\"\n<style>\n    .stButton button {\n        background-color: #4CAF50;\n        color: white;\n        padding: 0.5rem 1rem;\n        border-radius: 5px;\n        border: none;\n        box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n        transition: all 0.3s ease;\n    }\n    .stButton button:hover {\n        background-color: #45a049;\n        box-shadow: 0 4px 8px rgba(0,0,0,0.2);\n    }\n    div[data-testid=\"stDecoration\"] {\n        background-image: none;\n    }\n</style>\n\"\"\", unsafe_allow_html=True)\n\n# Initialize session and get data\nsession = get_active_session()\ndatabase = 'GEN_AI_FSI'\nschema = 'DTCC_HACKATHON'\ntable = 'CHANGE_REQUEST_RISK'\n\ndef color_risk_score(val):\n    \"\"\"\n    Returns a color based on the risk score value:\n    - Low risk (0-1): Green\n    - Medium risk (2-3): Yellow\n    - High risk (4-5): Red\n    \"\"\"\n    if pd.isna(val):\n        return ''\n    \n    # Normalize value between 0 and 1\n    normalized = float(val) / 10\n    \n    # Create RGB values for gradient\n    if normalized < 0.2:  # Green to Yellow\n        r = int(255 * (normalized / 0.2))\n        g = 255\n        b = 0\n    else:  # Yellow to Red\n        r = 255\n        g = int(255 * (1 - (normalized - 0.2) / 0.5))\n        b = 0\n    \n    return f'background-color: rgba({r}, {g}, {b}, 0.2)'\n\n@st.cache_data\ndef load_data():\n    df = session.table(f\"{database}.{schema}.{table}\").to_pandas()\n    for i in range(len(df)):\n        json_data = json.loads(df.at[i, 'RISK_ASSESSMENT'])\n        df.at[i, 'RISK_SCORE_AI'] = json_data[\"Risk_Score\"]\n        df.at[i, 'RISK_REASON_AI'] = json_data[\"Risk_Score_Reason\"]\n    return df\n\n# Load data\ndf = load_data()\n\n# Prepare display tables with styling\ndisplay_table = df[['CHANGENUMBER', 'DATE', 'RISK_SCORE_AI', 'RISK_REASON_AI']]\ndisplay_table_detail = df[['CHANGENUMBER', 'DESCRIPTION', 'DATE', 'IMPACT', \n                          'PRIORITY', 'RISK', 'JUSTIFICATION', 'STATE', \n                          'DISPOSITION', 'CATEGORY', 'RISK_SCORE_AI', 'RISK_REASON_AI']]\n\n# App header\nst.title('Risk Assessment Dashboard')\n\n# Add some basic metrics\nst.subheader('Key Metrics')\nmetric_col1, metric_col2, metric_col3 = st.columns(3)\n\nwith metric_col1:\n    avg_risk = df['RISK_SCORE_AI'].mean()\n    st.metric('Average Risk Score', f'{avg_risk:.2f}')\n\nwith metric_col2:\n    high_risk_count = len(df[df['RISK_SCORE_AI'] > 3])\n    st.metric('High Risk Changes', high_risk_count)\n\nwith metric_col3:\n    total_changes = len(df)\n    st.metric('Total Changes', total_changes)\n\n# Main content area\ncol1, col2 = st.columns([3, 1])\n\ntitle = 'Risk Assessment Summary'\n\nst.subheader(title)\nshow_details = st.button('Show Detailed View', use_container_width=True)\n    \n# Show detailed view if button is clicked\nif show_details:\n    title = 'Detailed Risk Assessment'\n    st.dataframe(\n        display_table_detail.style.applymap(\n            color_risk_score,\n            subset=['RISK_SCORE_AI']\n        ),\n        use_container_width=True,\n        hide_index=True,\n        height=400\n)\nelse: \n    st.dataframe(\n        display_table.style.applymap(\n            color_risk_score,\n            subset=['RISK_SCORE_AI']\n        ),\n        use_container_width=True,\n        hide_index=True,\n        height=400\n    )",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e541c9e-b51c-468a-95e3-999bda41df8c",
   "metadata": {
    "language": "python",
    "name": "py_full_application",
    "collapsed": false,
    "resultHeight": 733
   },
   "outputs": [],
   "source": "import streamlit as st\nimport json5 as json\nimport pandas as pd\nfrom snowflake.snowpark.functions import col, call_udf\nfrom snowflake.snowpark.context import get_active_session\n\n# Page configuration\n# st.set_page_config(\n#     page_title=\"Change Request Risk Assessment\",\n#     page_icon=\"🔍\",\n#     layout=\"wide\",\n#     initial_sidebar_state=\"expanded\"\n# )\n\n# Add legend for risk score colors\nst.sidebar.title('Risk Score Legend')\n\nfunctionality = st.sidebar.selectbox('Select Functionlity', (\"Summary\", \"Ad Hoc\"))\n\nlegend_cols = st.sidebar.columns(3)\nwith legend_cols[0]:\n    st.color_picker('Low Risk (0-2)', '#00FF00', disabled=True)\nwith legend_cols[1]:\n    st.color_picker('Medium Risk (2-3)', '#FFFF00', disabled=True)\nwith legend_cols[2]:\n    st.color_picker('High Risk (4-5)', '#FF0000', disabled=True)\n\n##########################\n##########AD HOC##########\n##########################\n\n# Custom CSS to enhance the UI\nst.markdown(\"\"\"\n    <style>\n    .risk-score {\n        font-size: 24px;\n        font-weight: bold;\n        padding: 1rem;\n        border-radius: 8px;\n        margin: 1rem 0;\n    }\n    .info-box {\n        background-color: #f8f9fa;\n        padding: 1.5rem;\n        border-radius: 8px;\n        box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n\n# Header with gradient background\nst.title(\"Change Request Risk Assessment\")\n\n# Initialize session\nsession = get_active_session()\n\ndef generate_risk_prediction_prompt(cr_data):\n    prompt = f\"\"\"\n            <role>\n            You are an experienced dev ops professional deeply knowledgeable on computer systems that support a very large company and the metadata that is captured about change requests.\n            A change request is a formal proposal for an alteration to the computer system that you manage.\n            As a dev ops expert, you specialize in using the metadata provided about a change request to predict the liklihood of the change request unintentionally destabalizing the computer system.\n            You are going to be provided with change request meta data as a json object held between <cr_data> and your job is to provide a prediction score and reasoning behind the risk score in the <output> section. \n            </role>\n        \n            <task>: Follow these instructions,\n            1) Considering the <cr_data> and your <role>, provide a risk score between 0 to 5 of this change request destabalizing the computer system when deployed. do not exhibit a bias toward high risk. base your risk score only on the data you have been provided. if there is not enough information, please indicate this. Output this as [Risk_Score]. Then,\n            2) Considering the <cr_data> and your <role>, provide a reasoning for the risk score in as few words as possible while maintaining all detail needed to understand your reasoning. Output this as [Risk_Score_Reason]\n            </task>\n\n            <cr_data>\n            {cr_data}\n            </cr_data>\n        \n            <Output> \n            produce valid JSON. Absolutely do not include any additional text before or following the JSON. Output should use following <JSON_format>\n            </Output>\n            \n            <JSON_format>\n            {{\n                \"Risk_Score\": (A risk score between 0 to 5 of this change request destabalizing the computer system when deployed),\n                \"Risk_Score_Reason\": (A concise resoning for the Risk_Score and any suggestions to mitigate),\n            }}\n            </JSON_format>\n            \"\"\"\n    return prompt\n\ndef my_complete(model, context, temp=0, max_tokens: int = 18000):\n    sql = F\"\"\"SELECT SNOWFLAKE.CORTEX.COMPLETE(\n            '{model}',\n            [\n                {{\n                    'role': 'user',\n                    'content': '{context}'\n                }}\n            ],\n            {{\n                'max_tokens': {max_tokens}, \n                'temperature' : {temp} \n            }}\n        ) as inference;\"\"\"\n    inference_raw = session.sql(sql).to_pandas().loc[0,\"INFERENCE\"]\n    inference_json = json.loads(inference_raw)\n    inference_raw = inference_json['choices'][0]['messages']\n    return inference_raw\n\n# Database configuration\ndatabase = 'GEN_AI_FSI'\nschema = 'DTCC_HACKATHON'\ntable = 'ChangeRequests'\nhistory_table = 'CHANGE_REQUEST_RISK'\n\n# Get the data into pandas\ncr_df = session.table(f\"{database}.{schema}.{table}\")\n\n# Create two columns for the input section\ncol1, col2 = st.columns(2)\n\nwith col1:\n    #st.markdown('<div class=\"info-box\">', unsafe_allow_html=True)\n    cr_request = st.selectbox(\n        'Select a Change Request',\n        cr_df,\n        help=\"Choose the change request you want to analyze\"\n    )\n    st.markdown('</div>', unsafe_allow_html=True)\n\nwith col2:\n    #st.markdown('<div class=\"info-box\">', unsafe_allow_html=True)\n    # Available models\n    models = [\n        'snowflake-arctic', 'claude-3-5-sonnet', 'mistral-large',\n        'mistral-large2', 'reka-flash', 'reka-core', 'jamba-instruct',\n        'jamba-1.5-mini', 'jamba-1.5-large', 'mixtral-8x7b',\n        'llama2-70b-chat', 'llama3-8b', 'llama3-70b', 'llama3.1-8b',\n        'llama3.1-70b', 'llama3.3-70b', 'snowflake-llama-3.3-70b',\n        'llama3.1-405b', 'snowflake-llama-3.1-405b', 'llama3.2-1b',\n        'llama3.2-3b', 'mistral-7b', 'gemma-7b'\n    ]\n    \n    user_input_model = st.selectbox(\n        \"Select AI Model\",\n        models,\n        help=\"Choose the AI model for risk assessment\",\n        key=\"CS_model_select_box\"\n    )\n    st.markdown('</div>', unsafe_allow_html=True)\n\n# Add a loading spinner\nwith st.spinner(\"Analyzing risk...\"):\n    df = session.table(f\"{database}.{schema}.{table}\").filter(col(\"CHANGENUMBER\") == cr_request).to_pandas()\n    \n    if st.button(\"Analyze Risk\", type=\"primary\"):\n        try:\n            df['RISK_ASSESSMENT'] = df.apply(\n                lambda row: my_complete(user_input_model, generate_risk_prediction_prompt(row.to_json())),\n                axis=1\n            )\n            \n            json_data = json.loads(df.at[0, 'RISK_ASSESSMENT'])\n            \n            # Create three columns for the results\n            result_col1, result_col2, result_col3 = st.columns([1,2,1])\n            \n            with result_col1:\n                #st.markdown('<div class=\"info-box\">', unsafe_allow_html=True)\n                # Color code the risk score\n                risk_score = float(json_data[\"Risk_Score\"])\n                color = \"green\" if risk_score <= 2 else \"orange\" if risk_score <= 3.5 else \"red\"\n                st.markdown(f'<div class=\"risk-score\" style=\"background-color: {color}; color: white;\">'\n                          f'Risk Score: {risk_score}</div>', unsafe_allow_html=True)\n                st.markdown('</div>', unsafe_allow_html=True)\n            \n            with result_col2:\n                #st.markdown('<div class=\"info-box\">', unsafe_allow_html=True)\n                st.subheader(\"Risk Assessment\")\n                st.write(json_data[\"Risk_Score_Reason\"])\n                st.markdown('</div>', unsafe_allow_html=True)\n            \n            with result_col3:\n                with st.expander(\"View Raw JSON\"):\n                #if st.button(\"View Raw JSON\"):\n                    st.json(json_data)\n\n        except ValueError as e:\n            st.error(f\"Error: {user_input_model} did not produce valid output. Please select another model.\")\n            st.exception(e)\n        except Exception as e:\n            st.error(\"An unexpected error occurred. Please try again.\")\n            st.exception(e)\n",
   "execution_count": null
  }
 ]
}